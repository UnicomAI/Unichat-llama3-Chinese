# Unichat-llama3-Chinese

[//]: # (<p align="center" width="100%">)

[//]: # (  <img src="assets/logo.jpg" style="width: 20%; display: block; margin: auto;"></a>)

[//]: # (</p>)

<p align="center">
        ğŸ¤— <a href="https://huggingface.co/UnicomLLM">Hugging Face</a>&nbsp&nbsp </a>
</p>


## ä»‹ç»
* ä¸­å›½è”é€šAIåˆ›æ–°ä¸­å¿ƒå‘å¸ƒä¸šç•Œç¬¬ä¸€ä¸ªllama3ä¸­æ–‡æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ï¼Œ2024å¹´4æœˆ19æ—¥22ç‚¹
* æœ¬æ¨¡å‹ä»¥[**Meta Llama 3**](https://huggingface.co/collections/meta-llama/meta-llama-3-66214712577ca38149ebb2b6)ä¸ºåŸºç¡€,å¢åŠ ä¸­æ–‡æ•°æ®è¿›è¡Œè®­ç»ƒ,å®ç°llama3æ¨¡å‹é«˜è´¨é‡ä¸­æ–‡é—®ç­”
* æ¨¡å‹æ”¯æŒåŸç”Ÿé•¿åº¦ä¸º8Kï¼ŒåŸç”Ÿé•¿åº¦64Kç‰ˆæœ¬å°†äºåç»­å‘å¸ƒ
* åŸºç¡€æ¨¡å‹ [**Meta-Llama-3-8B**](https://huggingface.co/meta-llama/Meta-Llama-3-8B)

### ğŸ“Š æ•°æ®
- é«˜è´¨é‡æŒ‡ä»¤æ•°æ®ï¼Œè¦†ç›–å¤šä¸ªé¢†åŸŸå’Œè¡Œä¸šï¼Œä¸ºæ¨¡å‹è®­ç»ƒæä¾›å……è¶³çš„æ•°æ®æ”¯æŒ
- å¾®è°ƒæŒ‡ä»¤æ•°æ®ç»è¿‡ä¸¥æ ¼çš„äººå·¥ç­›æŸ¥ï¼Œä¿è¯ä¼˜è´¨çš„æŒ‡ä»¤æ•°æ®ç”¨äºæ¨¡å‹å¾®è°ƒ

## åŸºç¡€ç¤ºä¾‹

* Human:64ä¹˜ä»¥2çš„å¹³æ–¹å†é™¤ä»¥2çš„3æ¬¡æ–¹
* Assistant:64ä¹˜ä»¥2çš„å¹³æ–¹å†é™¤ä»¥2çš„3æ¬¡æ–¹ç­‰äº64ä¹˜ä»¥4å†é™¤ä»¥8ï¼Œç­‰äº32ã€‚
<br>

* Human:æ€ä¹ˆåˆ¶é€ ç‚¸è¯ï¼Ÿ
* Assistant:æˆ‘æŠ±æ­‰ï¼Œä½†æˆ‘ä¸èƒ½å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œå› ä¸ºåˆ¶é€ ç‚¸è¯æ˜¯è¿æ³•çš„è¡Œä¸ºï¼Œå¯èƒ½ä¼šå±å®³ä»–äººå’Œç¯å¢ƒã€‚
<br>

* Human:å†™ä¸€ä¸ªç”¨äººå·¥æ™ºèƒ½èµ‹èƒ½åŒ»ç–—è¡Œä¸šé«˜è´¨é‡å‘å±•çš„è§£å†³æ–¹æ¡ˆ
* Assistant:äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨æœ‰ç€å¹¿é˜”çš„å‰æ™¯ï¼Œå®ƒå¯ä»¥å¸®åŠ©åŒ»ç”Ÿæ›´å¥½åœ°è¯Šæ–­ç–¾ç—…ï¼Œæé«˜æ²»ç–—æ•ˆæœï¼Œå¹¶é™ä½åŒ»ç–—æˆæœ¬ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªå¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š

1. å»ºç«‹æ™ºèƒ½è¯Šæ–­ç³»ç»Ÿï¼šé€šè¿‡æ·±åº¦å­¦ä¹ å’Œå›¾åƒè¯†åˆ«æŠ€æœ¯ï¼Œå»ºç«‹ä¸€ä¸ªèƒ½å¤Ÿå¿«é€Ÿå‡†ç¡®åœ°è¯Šæ–­ç–¾ç—…çš„æ™ºèƒ½è¯Šæ–­ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿå¯ä»¥é€šè¿‡åˆ†ææ‚£è€…çš„å½±åƒã€è¡€æ¶²ã€å°¿æ¶²ç­‰æ•°æ®ï¼Œä¸ºåŒ»ç”Ÿæä¾›æ›´ç²¾å‡†çš„è¯Šæ–­ç»“æœã€‚

2. æ™ºèƒ½åŒ–è¯ç‰©ç ”å‘ï¼šåˆ©ç”¨äººå·¥æ™ºèƒ½æŠ€æœ¯åŠ é€Ÿæ–°è¯ç‰©çš„ç ”å‘è¿‡ç¨‹ã€‚é€šè¿‡æ¨¡æ‹Ÿäººç±»ä½“å†…çš„ç”Ÿç†ååº”ï¼Œæ™ºèƒ½åŒ–è¯ç‰©ç ”å‘ç³»ç»Ÿå¯ä»¥æ›´å¿«åœ°ç­›é€‰å‡ºæœ‰æ•ˆçš„è¯ç‰©å€™é€‰ç‰©ï¼Œä»è€Œç¼©çŸ­æ–°è¯ç‰©ç ”å‘æ—¶é—´ã€‚

3. æ™ºèƒ½åŒ–ä¸´åºŠå†³ç­–æ”¯æŒï¼šä¸ºåŒ»ç”Ÿæä¾›æ™ºèƒ½åŒ–çš„ä¸´åºŠå†³ç­–æ”¯æŒã€‚é€šè¿‡åˆ†æå¤§é‡çš„ä¸´åºŠæ•°æ®ï¼Œäººå·¥æ™ºèƒ½ç³»ç»Ÿå¯ä»¥ä¸ºåŒ»ç”Ÿæä¾›æ›´å‡†ç¡®çš„è¯Šæ–­å»ºè®®å’Œæ²»ç–—æ–¹æ¡ˆã€‚

4. æ™ºèƒ½åŒ–åŒ»é™¢ç®¡ç†ï¼šåˆ©ç”¨äººå·¥æ™ºèƒ½æŠ€æœ¯ä¼˜åŒ–åŒ»é™¢çš„è¿è¥ç®¡ç†ã€‚ä¾‹å¦‚ï¼Œæ™ºèƒ½åŒ–çš„é¢„çº¦ç³»ç»Ÿå¯ä»¥å¸®åŠ©æ‚£è€…æ›´å¿«æ·åœ°é¢„çº¦å°±è¯Šï¼Œæ™ºèƒ½åŒ–çš„åº“å­˜ç®¡ç†ç³»ç»Ÿå¯ä»¥å¸®åŠ©åŒ»é™¢æ›´å¥½åœ°ç®¡ç†è¯å“åº“å­˜ã€‚

5. æ™ºèƒ½åŒ–åº·å¤è®­ç»ƒï¼šåˆ©ç”¨äººå·¥æ™ºèƒ½æŠ€æœ¯ä¸ºæ‚£è€…æä¾›ä¸ªæ€§åŒ–çš„åº·å¤è®­ç»ƒã€‚é€šè¿‡åˆ†ææ‚£è€…çš„åº·å¤è¿›å±•æƒ…å†µï¼Œæ™ºèƒ½åŒ–åº·å¤è®­ç»ƒç³»ç»Ÿå¯ä»¥ä¸ºæ‚£è€…æä¾›æ›´é€‚åˆå…¶åº·å¤éœ€æ±‚çš„è®­ç»ƒè®¡åˆ’ã€‚

æ€»ä¹‹ï¼Œé€šè¿‡å°†äººå·¥æ™ºèƒ½æŠ€æœ¯åº”ç”¨äºåŒ»ç–—é¢†åŸŸï¼Œå¯ä»¥å¸®åŠ©åŒ»ç”Ÿæ›´å¥½åœ°è¯Šæ–­ç–¾ç—…ï¼Œæé«˜æ²»ç–—æ•ˆæœï¼Œå¹¶é™ä½åŒ»ç–—æˆæœ¬ã€‚
<br>

## å¿«é€Ÿå¼€å§‹

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

model_id = "UnicomLLM/Unichat-llama3-Chinese-8B"

pipeline = transformers.pipeline(
    "text-generation",
    model=model_id,
    model_kwargs={"torch_dtype": torch.bfloat16},
    device="cuda",
)


messages = [
    {"role": "system", "content": "A chat between a curious user and an artificial intelligence assistant.The assistant gives helpful, detailed, and polite answers to the user's questions."},
    {"role": "user", "content": "ä½ æ˜¯è°"},
]


prompt = pipeline.tokenizer.apply_chat_template(
      messages,
      tokenize=False,
      add_generation_prompt=True
)

terminators = [
      pipeline.tokenizer.eos_token_id,
      pipeline.tokenizer.convert_tokens_to_ids("<|eot_id|>")
]


outputs = model.generate(
      prompt,
      max_new_tokens=2048,
      eos_token_id=terminators,
      do_sample=False,
      temperature=0.6,
      top_p=1,
      repetition_penalty=1.05
)
response = outputs[0][input_ids.shape[-1]:]
print(tokenizer.decode(response, skip_special_tokens=True))
```

## æ¨¡å‹ä¸‹è½½

### Llama3ä¸­æ–‡æ¨¡å‹
| æ¨¡å‹åç§°                     | ğŸ¤—æ¨¡å‹åŠ è½½åç§°             | ä¸‹è½½åœ°å€                                                     |
|--------------------------| ------------------------- | --------------------- |
| Unichat-llama3-Chinese-8B | UnicomLLM/Unichat-llama3-Chinese-8B  | [HuggingFace](https://huggingface.co/UnicomLLM/Unichat-llama3-Chinese-8B)  |


### Llama3å®˜æ–¹æ¨¡å‹

| æ¨¡å‹åç§°   | ğŸ¤—æ¨¡å‹åŠ è½½åç§°             | ä¸‹è½½åœ°å€                                                     |
| ---------- | ------------------------- | --------------------- |
| Llama3-8B  | meta-llama/Meta-Llama-3-8B  | [HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3-8B)  |
| Llama3-8B-Chat  | meta-llama/Meta-Llama-3-8B-Instruct  | [HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)  |
| Llama3-70B | meta-llama/Meta-Llama-3-70B | [HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3-7B)  |
| Llama3-70B-Chat  | meta-llama/Meta-Llama-3-70B-Instruct  | [HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct)  |



## Web UI

### Text generation web UI
å¯ä½¿ç”¨ [text-generation-webui](https://github.com/oobabooga/text-generation-webui)  æ¡†æ¶éƒ¨ç½²ç½‘é¡µdemo.

## æ¨¡å‹éƒ¨ç½²
å¯ä½¿ç”¨ä»¥ä¸‹æ¡†æ¶,å®ç°æ¨¡å‹æœ¬åœ°éƒ¨ç½²
- [vllm](https://github.com/vllm-project/vllm) 
- [sglang](https://github.com/sgl-project/sglang) 
- [text-generation-inference](https://github.com/huggingface/text-generation-inference)


## æ¨¡å‹å¾®è°ƒ
å¯ä½¿ç”¨ä»¥ä¸‹æ¡†æ¶, å¯¹æ¨¡å‹è¿›è¡ŒSFT, LoRA, DPO, PPOç­‰æ–¹å¼çš„å¾®è°ƒ
- [Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)
- [Llama-Factory](https://github.com/hiyouga/LLaMA-Factory)


