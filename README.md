# Unichat-llama3-Chinese

[//]: # (<p align="center" width="100%">)

[//]: # (  <img src="assets/logo.jpg" style="width: 20%; display: block; margin: auto;"></a>)

[//]: # (</p>)

<p align="center">
        ğŸ¤— <a href="https://huggingface.co/UnicomLLM">Hugging Face</a>&nbsp&nbsp </a>
</p>

## ä»‹ç»
* ä¸­å›½è”é€šå‘å¸ƒä¸šç•Œç¬¬ä¸€ä¸ªllama3ä¸­æ–‡æ¨¡å‹
* æœ¬æ¨¡å‹ä»¥[**Meta Llama 3**](https://huggingface.co/collections/meta-llama/meta-llama-3-66214712577ca38149ebb2b6)ä¸ºåŸºç¡€,å¢åŠ ä¸­æ–‡æ•°æ®è¿›è¡Œè®­ç»ƒ,å®ç°llama3æ¨¡å‹é«˜è´¨é‡ä¸­æ–‡é—®ç­”


### ğŸ“Š æ•°æ®
- ä¸­å›½è”é€šè‡ªæœ‰æ•°æ®ï¼Œè¦†ç›–å¤šä¸ªé¢†åŸŸå’Œè¡Œä¸šï¼Œä¸ºæ¨¡å‹è®­ç»ƒæä¾›å……è¶³çš„æ•°æ®æ”¯æŒã€‚
- åŸºäºä¸­å›½è”é€šç»Ÿä¸€æ•°æ®ä¸­å°ï¼Œå½’é›†å…¬å¸å†…å¤–éƒ¨ç­‰å¤šç§ç±»å‹æ•°æ®ï¼Œæ„å»ºä¸­å›½è”é€šé«˜è´¨é‡æ•°æ®é›†


### æœ€æ–°åŠ¨æ€
2024å¹´04æœˆ19æ—¥ï¼š ç¬¬ä¸€ç‰ˆæ¨¡å‹å‘å¸ƒ [**Unichat-llama3-Chinese**](https://huggingface.co/UnicomLLM)

## å¿«é€Ÿå¼€å§‹

### ğŸ¤— Hugging Face Transformers
```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
model_id = "UnicomLLM/Unichat-llama3-Chinese-8B"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.bfloat16,
    device_map="auto",
)
messages = [
    {"role": "system", "content": "You are a helpful assistant"},
    {"role": "user", "content": "Who are you?"},
]
input_ids = tokenizer.apply_chat_template(
    messages,
    add_generation_prompt=True,
    return_tensors="pt"
).to(model.device)
terminators = [
    tokenizer.eos_token_id,
    tokenizer.convert_tokens_to_ids("<|eot_id|>")
]
outputs = model.generate(
    input_ids,
    max_new_tokens=256,
    eos_token_id=terminators,
    do_sample=True,
    temperature=0.6,
    top_p=0.9,
)
response = outputs[0][input_ids.shape[-1]:]
print(tokenizer.decode(response, skip_special_tokens=True))
```


## æ¨¡å‹ä¸‹è½½

### Llama3ä¸­æ–‡æ¨¡å‹
| æ¨¡å‹åç§°                     | ğŸ¤—æ¨¡å‹åŠ è½½åç§°             | ä¸‹è½½åœ°å€                                                     |
|--------------------------| ------------------------- | --------------------- |
| Unichat-llama3-Chinese-8B | UnicomLLM/Unichat-llama3-Chinese-8B  | [HuggingFace](https://huggingface.co/UnicomLLM/Unichat-llama3-Chinese-8B)  |


### Llama3å®˜æ–¹æ¨¡å‹

| æ¨¡å‹åç§°   | ğŸ¤—æ¨¡å‹åŠ è½½åç§°             | ä¸‹è½½åœ°å€                                                     |
| ---------- | ------------------------- | --------------------- |
| Llama3-8B  | meta-llama/Meta-Llama-3-8B  | [HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3-8B)  |
| Llama3-8B-Chat  | meta-llama/Meta-Llama-3-8B-Instruct  | [HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)  |
| Llama3-70B | meta-llama/Meta-Llama-3-70B | [HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3-7B)  |
| Llama3-70B-Chat  | meta-llama/Meta-Llama-3-70B-Instruct  | [HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct)  |



## Web UI

### Text generation web UI
å¯ä½¿ç”¨ [text-generation-webui](https://github.com/oobabooga/text-generation-webui)  æ¡†æ¶éƒ¨ç½²ç½‘é¡µdemo.

## æ¨¡å‹éƒ¨ç½²
å¯ä½¿ç”¨ä»¥ä¸‹æ¡†æ¶,å®ç°æ¨¡å‹æœ¬åœ°éƒ¨ç½²
- [vllm](https://github.com/vllm-project/vllm) 
- [sglang](https://github.com/sgl-project/sglang) 
- [text-generation-inference](https://github.com/huggingface/text-generation-inference)


## æ¨¡å‹å¾®è°ƒ
å¯ä½¿ç”¨ä»¥ä¸‹æ¡†æ¶, å¯¹æ¨¡å‹è¿›è¡ŒSFT, LoRA, DPO, PPOç­‰æ–¹å¼çš„å¾®è°ƒ
- [Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)
- [Llama-Factory](https://github.com/hiyouga/LLaMA-Factory)


